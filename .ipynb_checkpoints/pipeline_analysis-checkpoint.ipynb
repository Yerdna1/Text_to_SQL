{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM DB2 Sales Pipeline Analytics Demo\n",
    "\n",
    "This notebook demonstrates SQL queries on IBM sales pipeline data and generates visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ðŸ“š Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Demo Database and Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create demo database\n",
    "conn = sqlite3.connect(':memory:')  # In-memory database\n",
    "\n",
    "# Sample Pipeline data based on IBM MQT structure\n",
    "pipeline_data = {\n",
    "    'CALL_AMT': [100000, 0, 250000, 0, 500000, 150000, 0, 300000, 0, 750000],\n",
    "    'WON_AMT': [0, 0, 0, 250000, 0, 0, 180000, 0, 400000, 0],\n",
    "    'UPSIDE_AMT': [0, 150000, 0, 0, 0, 0, 0, 200000, 0, 0],\n",
    "    'QUALIFY_PLUS_AMT': [100000, 150000, 250000, 250000, 500000, 150000, 180000, 500000, 400000, 750000],\n",
    "    'OPPORTUNITY_VALUE': [120000, 180000, 300000, 250000, 600000, 200000, 180000, 500000, 400000, 800000],\n",
    "    'PPV_AMT': [80000, 90000, 200000, 250000, 400000, 120000, 180000, 300000, 400000, 600000],\n",
    "    'SALES_STAGE': ['Negotiate', 'Propose', 'Closing', 'Won', 'Qualify', 'Closing', 'Won', 'Propose', 'Won', 'Closing'],\n",
    "    'GEOGRAPHY': ['Americas', 'Americas', 'EMEA', 'APAC', 'Americas', 'EMEA', 'APAC', 'Americas', 'EMEA', 'Americas'],\n",
    "    'MARKET': ['US Federal', 'US Commercial', 'UK Market', 'Japan Market', 'Canada Market', 'Germany Market', 'Australia', 'US Federal', 'France', 'US Commercial'],\n",
    "    'CLIENT_NAME': ['Federal Agency A', 'Corp B', 'UK Corp C', 'Japan Inc', 'Canada Ltd', 'German Co', 'Aussie Corp', 'Federal Agency B', 'French Co', 'Big Corp'],\n",
    "    'DEAL_SIZE': ['large', 'medium', 'large', 'medium', 'large', 'medium', 'small', 'large', 'large', 'large'],\n",
    "    'INDUSTRY': ['Government', 'Financial', 'Manufacturing', 'Technology', 'Healthcare', 'Automotive', 'Retail', 'Government', 'Energy', 'Financial'],\n",
    "    'UT17_NAME': ['Cybersecurity', 'Hybrid Cloud & Data', 'Strategy & Transformation', 'AI/ML Ops', 'Application Operations', 'Business Applications', 'Data Fabric', 'Cybersecurity', 'Strategy & Transformation', 'Hybrid Cloud & Data'],\n",
    "    'YEAR': [2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 2025],\n",
    "    'QUARTER': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    'WEEK': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
    "}\n",
    "\n",
    "pipeline_df = pd.DataFrame(pipeline_data)\n",
    "pipeline_df.to_sql('PROD_MQT_CONSULTING_PIPELINE', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Sample Budget data\n",
    "budget_data = {\n",
    "    'GEOGRAPHY': ['Americas', 'EMEA', 'APAC', 'Americas', 'EMEA', 'APAC'],\n",
    "    'MARKET': ['US Federal', 'UK Market', 'Japan Market', 'US Commercial', 'Germany Market', 'Australia'],\n",
    "    'REVENUE_BUDGET_AMT': [2000000, 1500000, 1200000, 1800000, 1000000, 800000],\n",
    "    'YEAR': [2025, 2025, 2025, 2025, 2025, 2025],\n",
    "    'QUARTER': [1, 1, 1, 1, 1, 1]\n",
    "}\n",
    "\n",
    "budget_df = pd.DataFrame(budget_data)\n",
    "budget_df.to_sql('PROD_MQT_CONSULTING_BUDGET', conn, if_exists='replace', index=False)\n",
    "\n",
    "print(\"âœ… Demo tables created successfully\")\n",
    "print(f\"Pipeline table: {len(pipeline_df)} rows\")\n",
    "print(f\"Budget table: {len(budget_df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Execute Sample Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1: What is the total value of deals currently in the pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"\"\"\n",
    "SELECT \n",
    "    SUM(OPPORTUNITY_VALUE) / 1000000.0 AS TOTAL_PIPELINE_M,\n",
    "    SUM(QUALIFY_PLUS_AMT) / 1000000.0 AS QUALIFIED_PIPELINE_M,\n",
    "    SUM(PPV_AMT) / 1000000.0 AS PREDICTED_PIPELINE_M,\n",
    "    COUNT(DISTINCT CLIENT_NAME) AS UNIQUE_CLIENTS,\n",
    "    COUNT(*) AS TOTAL_OPPORTUNITIES\n",
    "FROM \n",
    "    PROD_MQT_CONSULTING_PIPELINE\n",
    "WHERE \n",
    "    SALES_STAGE NOT IN ('Won', 'Lost');\n",
    "\"\"\"\n",
    "\n",
    "df1 = pd.read_sql_query(query1, conn)\n",
    "print(\"ðŸ“Š TOTAL PIPELINE VALUE:\")\n",
    "print(f\"Total Pipeline: ${df1['TOTAL_PIPELINE_M'].iloc[0]:.2f}M\")\n",
    "print(f\"Qualified Pipeline: ${df1['QUALIFIED_PIPELINE_M'].iloc[0]:.2f}M\")\n",
    "print(f\"Predicted Pipeline (PPV): ${df1['PREDICTED_PIPELINE_M'].iloc[0]:.2f}M\")\n",
    "print(f\"Unique Clients: {df1['UNIQUE_CLIENTS'].iloc[0]}\")\n",
    "print(f\"Total Opportunities: {df1['TOTAL_OPPORTUNITIES'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2: Pipeline by Geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"\"\"\n",
    "SELECT \n",
    "    GEOGRAPHY,\n",
    "    SUM(OPPORTUNITY_VALUE) / 1000000.0 AS PIPELINE_M,\n",
    "    SUM(QUALIFY_PLUS_AMT) / 1000000.0 AS QUALIFIED_M,\n",
    "    SUM(PPV_AMT) / 1000000.0 AS FORECAST_M,\n",
    "    COUNT(*) AS DEAL_COUNT,\n",
    "    COUNT(DISTINCT CLIENT_NAME) AS CLIENT_COUNT\n",
    "FROM \n",
    "    PROD_MQT_CONSULTING_PIPELINE\n",
    "WHERE \n",
    "    SALES_STAGE NOT IN ('Won', 'Lost')\n",
    "GROUP BY \n",
    "    GEOGRAPHY\n",
    "ORDER BY \n",
    "    PIPELINE_M DESC;\n",
    "\"\"\"\n",
    "\n",
    "df2 = pd.read_sql_query(query2, conn)\n",
    "print(\"ðŸŒ PIPELINE BY GEOGRAPHY:\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3: Sales Stage Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = \"\"\"\n",
    "SELECT \n",
    "    SALES_STAGE,\n",
    "    COUNT(*) AS DEAL_COUNT,\n",
    "    SUM(OPPORTUNITY_VALUE) / 1000000.0 AS STAGE_VALUE_M,\n",
    "    AVG(OPPORTUNITY_VALUE) / 1000.0 AS AVG_DEAL_SIZE_K,\n",
    "    ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM PROD_MQT_CONSULTING_PIPELINE), 1) AS PCT_OF_DEALS\n",
    "FROM \n",
    "    PROD_MQT_CONSULTING_PIPELINE\n",
    "GROUP BY \n",
    "    SALES_STAGE\n",
    "ORDER BY \n",
    "    CASE SALES_STAGE\n",
    "        WHEN 'Won' THEN 1\n",
    "        WHEN 'Closing' THEN 2\n",
    "        WHEN 'Negotiate' THEN 3\n",
    "        WHEN 'Propose' THEN 4\n",
    "        WHEN 'Qualify' THEN 5\n",
    "        ELSE 6\n",
    "    END;\n",
    "\"\"\"\n",
    "\n",
    "df3 = pd.read_sql_query(query3, conn)\n",
    "print(\"ðŸ“ˆ SALES STAGE DISTRIBUTION:\")\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 4: Win Rate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query4 = \"\"\"\n",
    "SELECT \n",
    "    GEOGRAPHY,\n",
    "    SUM(CASE WHEN SALES_STAGE = 'Won' THEN 1 ELSE 0 END) AS WON_DEALS,\n",
    "    COUNT(*) AS TOTAL_DEALS,\n",
    "    ROUND(SUM(CASE WHEN SALES_STAGE = 'Won' THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 1) AS WIN_RATE_PCT,\n",
    "    SUM(CASE WHEN SALES_STAGE = 'Won' THEN OPPORTUNITY_VALUE ELSE 0 END) / 1000000.0 AS WON_VALUE_M\n",
    "FROM \n",
    "    PROD_MQT_CONSULTING_PIPELINE\n",
    "GROUP BY \n",
    "    GEOGRAPHY\n",
    "ORDER BY \n",
    "    WIN_RATE_PCT DESC;\n",
    "\"\"\"\n",
    "\n",
    "df4 = pd.read_sql_query(query4, conn)\n",
    "print(\"ðŸ† WIN RATE BY GEOGRAPHY:\")\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 5: Forecast vs Budget Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query5 = \"\"\"\n",
    "SELECT \n",
    "    p.GEOGRAPHY,\n",
    "    p.MARKET,\n",
    "    SUM(p.PPV_AMT) / 1000000.0 AS FORECASTED_REVENUE_M,\n",
    "    b.REVENUE_BUDGET_AMT / 1000000.0 AS BUDGET_REVENUE_M,\n",
    "    ROUND((SUM(p.PPV_AMT) / b.REVENUE_BUDGET_AMT) * 100, 1) AS FORECAST_TO_BUDGET_PCT,\n",
    "    SUM(p.WON_AMT) / 1000000.0 AS WON_TO_DATE_M\n",
    "FROM \n",
    "    PROD_MQT_CONSULTING_PIPELINE p\n",
    "LEFT JOIN \n",
    "    PROD_MQT_CONSULTING_BUDGET b\n",
    "    ON p.GEOGRAPHY = b.GEOGRAPHY \n",
    "    AND p.MARKET = b.MARKET\n",
    "    AND p.YEAR = b.YEAR\n",
    "    AND p.QUARTER = b.QUARTER\n",
    "WHERE \n",
    "    b.REVENUE_BUDGET_AMT IS NOT NULL\n",
    "GROUP BY \n",
    "    p.GEOGRAPHY, p.MARKET, b.REVENUE_BUDGET_AMT\n",
    "ORDER BY \n",
    "    FORECAST_TO_BUDGET_PCT DESC;\n",
    "\"\"\"\n",
    "\n",
    "df5 = pd.read_sql_query(query5, conn)\n",
    "print(\"ðŸŽ¯ FORECAST VS BUDGET:\")\n",
    "print(df5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive dashboard\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('IBM Sales Pipeline Analytics Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Pipeline by Geography\n",
    "ax1 = axes[0, 0]\n",
    "df2.plot(x='GEOGRAPHY', y=['PIPELINE_M', 'QUALIFIED_M', 'FORECAST_M'], \n",
    "         kind='bar', ax=ax1, width=0.8)\n",
    "ax1.set_title('Pipeline by Geography ($M)', fontweight='bold')\n",
    "ax1.set_ylabel('Amount ($M)')\n",
    "ax1.legend(['Total Pipeline', 'Qualified', 'Forecast'])\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Sales Stage Distribution (Pie Chart)\n",
    "ax2 = axes[0, 1]\n",
    "ax2.pie(df3['DEAL_COUNT'], labels=df3['SALES_STAGE'], autopct='%1.1f%%', startangle=90)\n",
    "ax2.set_title('Deal Distribution by Stage', fontweight='bold')\n",
    "\n",
    "# 3. Win Rate vs Won Value (Scatter)\n",
    "ax3 = axes[0, 2]\n",
    "scatter = ax3.scatter(df4['WIN_RATE_PCT'], df4['WON_VALUE_M'], \n",
    "                     s=df4['WON_VALUE_M']*100, alpha=0.6, c=['red', 'blue', 'green'])\n",
    "for idx, row in df4.iterrows():\n",
    "    ax3.annotate(row['GEOGRAPHY'], (row['WIN_RATE_PCT'], row['WON_VALUE_M']),\n",
    "                fontsize=10, ha='center')\n",
    "ax3.set_xlabel('Win Rate (%)')\n",
    "ax3.set_ylabel('Won Value ($M)')\n",
    "ax3.set_title('Win Rate vs Won Value', fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Forecast vs Budget\n",
    "ax4 = axes[1, 0]\n",
    "x = np.arange(len(df5))\n",
    "width = 0.35\n",
    "ax4.bar(x - width/2, df5['FORECASTED_REVENUE_M'], width, label='Forecast', color='lightblue')\n",
    "ax4.bar(x + width/2, df5['BUDGET_REVENUE_M'], width, label='Budget', color='lightcoral')\n",
    "ax4.set_xlabel('Market')\n",
    "ax4.set_ylabel('Amount ($M)')\n",
    "ax4.set_title('Forecast vs Budget by Market', fontweight='bold')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(df5['MARKET'], rotation=45, ha='right')\n",
    "ax4.legend()\n",
    "\n",
    "# Add coverage percentage labels\n",
    "for i, pct in enumerate(df5['FORECAST_TO_BUDGET_PCT']):\n",
    "    ax4.text(i, max(df5['FORECASTED_REVENUE_M'].iloc[i], df5['BUDGET_REVENUE_M'].iloc[i]) + 0.05,\n",
    "            f'{pct}%', ha='center', fontweight='bold', fontsize=9)\n",
    "\n",
    "# 5. Industry Distribution\n",
    "ax5 = axes[1, 1]\n",
    "industry_query = \"\"\"\n",
    "SELECT \n",
    "    INDUSTRY,\n",
    "    SUM(OPPORTUNITY_VALUE) / 1000000.0 AS PIPELINE_M,\n",
    "    COUNT(*) AS DEAL_COUNT\n",
    "FROM \n",
    "    PROD_MQT_CONSULTING_PIPELINE\n",
    "WHERE \n",
    "    SALES_STAGE NOT IN ('Won', 'Lost')\n",
    "GROUP BY \n",
    "    INDUSTRY\n",
    "ORDER BY \n",
    "    PIPELINE_M DESC;\n",
    "\"\"\"\n",
    "df_industry = pd.read_sql_query(industry_query, conn)\n",
    "\n",
    "# Horizontal bar chart for industries\n",
    "y_pos = np.arange(len(df_industry))\n",
    "ax5.barh(y_pos, df_industry['PIPELINE_M'], color='green', alpha=0.7)\n",
    "ax5.set_yticks(y_pos)\n",
    "ax5.set_yticklabels(df_industry['INDUSTRY'])\n",
    "ax5.set_xlabel('Pipeline Value ($M)')\n",
    "ax5.set_title('Pipeline by Industry', fontweight='bold')\n",
    "\n",
    "# 6. Service Line Performance\n",
    "ax6 = axes[1, 2]\n",
    "service_query = \"\"\"\n",
    "SELECT \n",
    "    UT17_NAME,\n",
    "    SUM(OPPORTUNITY_VALUE) / 1000000.0 AS PIPELINE_M,\n",
    "    COUNT(*) AS DEAL_COUNT\n",
    "FROM \n",
    "    PROD_MQT_CONSULTING_PIPELINE\n",
    "WHERE \n",
    "    SALES_STAGE NOT IN ('Won', 'Lost')\n",
    "GROUP BY \n",
    "    UT17_NAME\n",
    "ORDER BY \n",
    "    PIPELINE_M DESC;\n",
    "\"\"\"\n",
    "df_service = pd.read_sql_query(service_query, conn)\n",
    "\n",
    "ax6.pie(df_service['PIPELINE_M'], labels=df_service['UT17_NAME'], autopct='%1.1f%%', startangle=90)\n",
    "ax6.set_title('Pipeline by Service Line', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Dashboard created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Executive Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“‹ EXECUTIVE SUMMARY REPORT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Key metrics\n",
    "total_pipeline = df1['TOTAL_PIPELINE_M'].iloc[0]\n",
    "qualified_pipeline = df1['QUALIFIED_PIPELINE_M'].iloc[0]\n",
    "predicted_revenue = df1['PREDICTED_PIPELINE_M'].iloc[0]\n",
    "unique_clients = df1['UNIQUE_CLIENTS'].iloc[0]\n",
    "\n",
    "print(f\"\\nðŸŽ¯ KEY METRICS:\")\n",
    "print(f\"   Total Pipeline: ${total_pipeline:.2f}M\")\n",
    "print(f\"   Qualified Pipeline: ${qualified_pipeline:.2f}M\")\n",
    "print(f\"   Forecasted Revenue (PPV): ${predicted_revenue:.2f}M\")\n",
    "print(f\"   Unique Clients: {unique_clients}\")\n",
    "\n",
    "# Top performing geography\n",
    "top_geo = df2.iloc[0]\n",
    "print(f\"\\nðŸŒŸ TOP PERFORMING GEOGRAPHY:\")\n",
    "print(f\"   {top_geo['GEOGRAPHY']}: ${top_geo['PIPELINE_M']:.2f}M pipeline\")\n",
    "print(f\"   {top_geo['CLIENT_COUNT']} clients, {top_geo['DEAL_COUNT']} deals\")\n",
    "\n",
    "# Win rate insights\n",
    "best_win_rate = df4.iloc[0]\n",
    "print(f\"\\nðŸ† WIN RATE LEADER:\")\n",
    "print(f\"   {best_win_rate['GEOGRAPHY']}: {best_win_rate['WIN_RATE_PCT']}% win rate\")\n",
    "print(f\"   Won Value: ${best_win_rate['WON_VALUE_M']:.2f}M\")\n",
    "\n",
    "# Budget performance\n",
    "avg_coverage = df5['FORECAST_TO_BUDGET_PCT'].mean()\n",
    "print(f\"\\nðŸ“Š BUDGET PERFORMANCE:\")\n",
    "print(f\"   Average Forecast Coverage: {avg_coverage:.1f}%\")\n",
    "if avg_coverage >= 100:\n",
    "    print(f\"   âœ… On track to meet targets\")\n",
    "elif avg_coverage >= 80:\n",
    "    print(f\"   âš ï¸ Slight gap to targets - need {100-avg_coverage:.1f}% more pipeline\")\n",
    "else:\n",
    "    print(f\"   ðŸš¨ Significant gap to targets - need {100-avg_coverage:.1f}% more pipeline\")\n",
    "\n",
    "# Action items\n",
    "print(f\"\\nðŸŽ¯ RECOMMENDED ACTIONS:\")\n",
    "print(f\"   1. Focus on {df2.iloc[-1]['GEOGRAPHY']} geography (lowest pipeline)\")\n",
    "print(f\"   2. Accelerate deals in {df3[df3['SALES_STAGE'].isin(['Qualify', 'Propose'])]['DEAL_COUNT'].sum()} early-stage opportunities\")\n",
    "print(f\"   3. Push {df3[df3['SALES_STAGE'] == 'Closing']['DEAL_COUNT'].iloc[0]} closing deals to Won\")\n",
    "print(f\"   4. Expand client base (currently {unique_clients} unique clients)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Additional Analysis Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query: Which deals need follow-up this week?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "followup_query = \"\"\"\n",
    "SELECT \n",
    "    CLIENT_NAME,\n",
    "    OPPORTUNITY_VALUE / 1000.0 AS VALUE_K,\n",
    "    SALES_STAGE,\n",
    "    GEOGRAPHY,\n",
    "    MARKET,\n",
    "    CASE \n",
    "        WHEN SALES_STAGE = 'Negotiate' AND CALL_AMT = 0 \n",
    "        THEN 'Critical - In Negotiate without commitment'\n",
    "        WHEN SALES_STAGE = 'Propose' AND UPSIDE_AMT > 0 \n",
    "        THEN 'High - Proposal needs push'\n",
    "        WHEN SALES_STAGE = 'Qualify' AND OPPORTUNITY_VALUE > 500000 \n",
    "        THEN 'High - Large deal in early stage'\n",
    "        ELSE 'Standard follow-up'\n",
    "    END AS FOLLOW_UP_PRIORITY,\n",
    "    CASE \n",
    "        WHEN SALES_STAGE = 'Negotiate' \n",
    "        THEN 'Schedule executive meeting to close'\n",
    "        WHEN SALES_STAGE = 'Propose' \n",
    "        THEN 'Address proposal questions and objections'\n",
    "        WHEN SALES_STAGE = 'Qualify' \n",
    "        THEN 'Confirm budget and decision criteria'\n",
    "        ELSE 'Standard check-in'\n",
    "    END AS RECOMMENDED_ACTION\n",
    "FROM \n",
    "    PROD_MQT_CONSULTING_PIPELINE\n",
    "WHERE \n",
    "    SALES_STAGE NOT IN ('Won', 'Lost', 'Closing')\n",
    "ORDER BY \n",
    "    CASE \n",
    "        WHEN SALES_STAGE = 'Negotiate' AND CALL_AMT = 0 THEN 1\n",
    "        WHEN SALES_STAGE = 'Propose' AND UPSIDE_AMT > 0 THEN 2\n",
    "        WHEN SALES_STAGE = 'Qualify' AND OPPORTUNITY_VALUE > 500000 THEN 3\n",
    "        ELSE 4\n",
    "    END,\n",
    "    OPPORTUNITY_VALUE DESC;\n",
    "\"\"\"\n",
    "\n",
    "df_followup = pd.read_sql_query(followup_query, conn)\n",
    "print(\"ðŸ“ž DEALS REQUIRING FOLLOW-UP:\")\n",
    "print(df_followup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query: Pipeline Health Score by Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_query = \"\"\"\n",
    "WITH pipeline_health AS (\n",
    "    SELECT \n",
    "        MARKET,\n",
    "        SUM(CASE WHEN SALES_STAGE = 'Closing' THEN OPPORTUNITY_VALUE ELSE 0 END) / \n",
    "            NULLIF(SUM(QUALIFY_PLUS_AMT), 0) * 100 AS CLOSING_PCT,\n",
    "        SUM(PPV_AMT) / NULLIF(SUM(QUALIFY_PLUS_AMT), 0) * 100 AS PPV_RATIO,\n",
    "        COUNT(DISTINCT CLIENT_NAME) AS CLIENT_DIVERSITY,\n",
    "        AVG(OPPORTUNITY_VALUE) / 1000000.0 AS AVG_DEAL_SIZE_M\n",
    "    FROM \n",
    "        PROD_MQT_CONSULTING_PIPELINE\n",
    "    WHERE \n",
    "        SALES_STAGE NOT IN ('Won', 'Lost')\n",
    "    GROUP BY \n",
    "        MARKET\n",
    "    HAVING \n",
    "        SUM(QUALIFY_PLUS_AMT) > 0\n",
    ")\n",
    "SELECT \n",
    "    MARKET,\n",
    "    ROUND(CLOSING_PCT, 1) AS CLOSING_PCT,\n",
    "    ROUND(PPV_RATIO, 1) AS PPV_RATIO,\n",
    "    CLIENT_DIVERSITY,\n",
    "    ROUND(AVG_DEAL_SIZE_M, 2) AS AVG_DEAL_SIZE_M,\n",
    "    ROUND((CLOSING_PCT * 0.4 + PPV_RATIO * 0.3 + \n",
    "     CASE WHEN CLIENT_DIVERSITY > 5 THEN 20 ELSE CLIENT_DIVERSITY * 4 END +\n",
    "     CASE WHEN AVG_DEAL_SIZE_M > 0.5 THEN 10 ELSE AVG_DEAL_SIZE_M * 20 END), 1) AS HEALTH_SCORE\n",
    "FROM \n",
    "    pipeline_health\n",
    "ORDER BY \n",
    "    HEALTH_SCORE DESC;\n",
    "\"\"\"\n",
    "\n",
    "df_health = pd.read_sql_query(health_query, conn)\n",
    "print(\"ðŸ’Š PIPELINE HEALTH SCORES:\")\n",
    "print(df_health)\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n",
    "print(\"\\nâœ… Demo completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}